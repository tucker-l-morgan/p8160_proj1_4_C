---
title: "P8160 - Comparing Bootstrapping Methods Report"
author: "Amy Pitts, Hun Lee, Jimmy Kelliher, Tucker Morgan, Waveley Qiu"
date: "2/11/2022"
output:
  pdf_document: default
header-includes: 
  - \usepackage{amsmath,amssymb,amsthm,amsfonts,bbm,graphics}
  - \usepackage{geometry}
  - \usepackage{tikz}
  - \usepackage{pgfplots}
  - \usetikzlibrary{shapes,arrows}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

**detail to be added**

# Simulation Planning

## Aims

The primary goal of this simulation study is to assess the performance of two bootstrap methods (detailed below) in estimating the sampling variability of treatment effects obtained from a nearest-neighbor propensity-score matching (NNM). In this study, NNM will select a treated subject at random from simulated observational data. The untreated subject with the nearest propensity score is then selected to be paired with the treated subject, without replacement. Treatment effects can then be estimated by comparing outcomes (continuous or binary) between the treated and untreated subjects. The bootstrapping methods will be used to assess the variance of estimated treatment effects.

## Data Generation

The data for this simulation study were generated from a parametric model. For each subject, three baseline covariates ($L_1, L_2, L_3$) were simulated from independent standard normal distributions, $N(0, 1)$. Two of these covariates ($L_1$ and $L_2$) affected treatment selection, while two ($L_2$ and $L_3$) affected the outcome. The probability of treatment for each subject was determined by the following model:
$$
\text{log}(\frac{\pi_i}{1 - \pi_i}) = \alpha_0 + \alpha_1 L_{1i} + \alpha_2 L_{2i}
$$


For continuous outcomes, 100 sub-populations of 100 or 1,000 subjects will be generated using the following parametric model:
$$
Y_i = \beta_1 A_i + \beta_2 L_{2i} + \beta_3 L_{3i} + \epsilon_i
$$
where $Y_i$ indicates the outcome for each subject, $A_i$ indicates the treatment status of each subject (0 or 1), $L_{2i}$ and $L_{3i}$ indicate observed covariate values for each subject, and $\epsilon_i$ denotes random error. Because $L_{2i}$ affects both $A_i$ and $Y_i$, it acts as a confounder in estimating the treatment effect.

For binary outcomes, the same procedure will be performed using the following parametric model:
$$
\text{log}(\frac{\tau_i}{1 - \tau_i}) = \beta_1 A_i + \beta_2 L_{2i} + \beta_3 L_{3i}
$$
where $Y_i \sim \text{Bernoulli}(\tau_i)$. The binary outcome model does not feature an error term, as realizations of $Y_i$ are innately subject to noise.

## Methods for Evaluation

Two bootstrap methods will be assessed in this simulation: the simple bootstrap and the complex bootstrap.

In the simple bootstrap, one draws repeated samples from an original sample with replacement to imitate the process of drawing samples from a population. Here, 500 repeated samples ($m_{boot}$) of matched pairs ($n_{boot} = n_{sample} \cdot P(A = 1)$) will be drawn from the matched pairs of observations for each of the 100 initial samples ($m_{sample}$). The distribution of the estimated treatment effect ($\hat{\beta_1}$) across the 500 bootstraps is assessed for each of the 100 initial samples.

The complex bootstrap considers two additional sources of variability compared to the simple bootstrap. In this approach, a sample is drawn with replacement from the original, unmatched observational data. The propensity-score model is estimated using this bootstrap sample, and NNM proceeds as before. The treatment effect is estimated from the newly matched sample. This process is repeated 500 times ($m_{boot}$) for each of the 100 samples ($m_{sample}$).

The resulting standard error estimates, $\hat{\sigma}_{\beta}$, will be the primary targets of this analysis.

```{tikz, echo = FALSE}
\tikzstyle{block} = [rectangle, draw, text width=5em, text centered, rounded corners, minimum height=3em]
\tikzstyle{line} = [draw, -latex]

\begin{tikzpicture}[node distance = 4cm, auto]
    % Place nodes
    \node [block] (init) {Data Generation};
    \node [block, above right of = init] (psm0) {PSM};
    \node [block, below right of = init] (bootc) {Bootstrap};
    \node [block, above right of = psm0] (base) {$\hat{\sigma}_\beta^2$};
    \node [block, below right of = psm0] (boots) {Bootstrap};
    \node [block, right of = bootc] (sampc1) {Unmatched Sample 1};
    \node [block, below of = sampc1, yshift = 2.25cm] (sampc2) {Unmatched Sample 2};
    \node [block, below of = sampc2, yshift = 2.25cm] (sampc3) {Unmatched Sample $m$};
    \node [block, right of = boots] (samps1) {Matched Sample $m$};
    \node [block, above of = samps1, yshift = -2.25cm] (samps2) {Matched Sample 2};
    \node [block, above of = samps2, yshift = -2.25cm] (samps3) {Matched Sample 1};
    \node [block, right of = samps2] (simp) {$\hat{\sigma}_\beta^2$};
    \node [block, right of = sampc1] (psm1) {PSM};
    \node [block, right of = sampc2] (psm2) {PSM};
    \node [block, right of = sampc3] (psm3) {PSM};
    \node [block, right of = psm2] (comp) {$\hat{\sigma}_\beta^2$};
    % Draw edges
    \path [line] (init) -- (psm0);
    \path [line] (init) -- node {Complex}(bootc);
    \path [line] (psm0) -- node {Baseline}(base);
    \path [line] (psm0) -- node {Simple}(boots);
    \path [line] (boots) -- (samps1);
    \path [line] (boots) -- (samps2);
    \path [line] (boots) -- (samps3);
    \path [line] (bootc) -- (sampc1);
    \path [line] (bootc) -- (sampc2);
    \path [line] (bootc) -- (sampc3);
    \path [line] (sampc1) -- (psm1);
    \path [line] (sampc2) -- (psm2);
    \path [line] (sampc3) -- (psm3);
    \path [line] (samps1) -- (simp);
    \path [line] (samps2) -- (simp);
    \path [line] (samps3) -- (simp);
    \path [line] (psm1) -- (comp);
    \path [line] (psm2) -- (comp);
    \path [line] (psm3) -- (comp);
\end{tikzpicture}
```

## Performance Measures

The standard error estimates from each bootstrap method will be assessed in two ways. First, coverage rates of confidence intervals will be analyzed to assess how frequently the true average treatment effect ($\beta_1$) is included in confidence intervals using the bootstrap-estimated treatment effect ($\bar{\hat{\beta_1}}$) and estimated standard errors ($\hat{\sigma}_{\beta}$). Second, standard error estimates from each bootstrap method will be compared to the sample standard deviation of treatment effects of the initial samples to determine how bootstrapping aligns with a simpler approach.

# Simulation Execution

**discussion of coding will go here, perhaps even excerpts of code**

# Results

**detail to be added**

# Discussion

**conclusions to be added**
