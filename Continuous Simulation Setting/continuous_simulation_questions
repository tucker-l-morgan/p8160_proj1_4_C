Open questions for continuous simulation:
1. Does it make sense for this setting to overestimate SE when we saw an underestimation for binary?
- Could be because PSM is strong with continuous outcome

2. Is there a way for us to mathematically determine the beta_0 intercept for this model similar to how we did in the binary model? Does this matter for our final performance measures?
- Similar results for very different coefficients, more in line with Hun's work on continuous in "Simple Bootstrap" folder.

(Amy attempting to answer question 2) If I understand correctly beta_0 is used to determine Y. So Y = beta_0 + beta_1*A + beta_2*L2 + beta_3*L3. The beta_0 will have no affect on our treatment effect because it is the same number for the treatment group and the control group. The only thing that is controlling treatment effect is beta_1. Since the continue case is a little more straight forward to the binary case our beta_1 estimate will be our treatment effect.  Please let me know if I miss interpreted your question. 

I think this makes sense! - TM

3. Now that I've removed the L3 coef from A ~, the data generation function pretty consistently breaks for large m. I get an error code "object 'mean_treated_proportion' not found". I had some success when increasing the tolerance from 0.001 to 0.05, but that eventually met issues as well. What could be going on with the function? Is it taking too long to find the solution coefficients? I am really not sure.
- well, it is now working, but I'm not sure why...